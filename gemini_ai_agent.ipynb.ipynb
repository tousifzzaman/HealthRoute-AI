{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 0: Install dependencies"
      ],
      "metadata": {
        "id": "K3yWWtQ8cC4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU google-generativeai==0.8.5 google-ai-generativelanguage==0.6.15 \\\n",
        "langgraph langchain langchain-google-genai openai\n"
      ],
      "metadata": {
        "id": "fgfnY6rpBCP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 1: Imports and secure API key input"
      ],
      "metadata": {
        "id": "XvoFPl11cFhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "VHCe-FE_C2rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Secure Gemini API Key input"
      ],
      "metadata": {
        "id": "W28u20SxcIiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['Google_API_key']=getpass.getpass(\"enter your gemini api key\")"
      ],
      "metadata": {
        "id": "7JxAjDogabZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 2: Initialize Gemini 1.5 Flash"
      ],
      "metadata": {
        "id": "eusINPuVcLXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"models/gemini-1.5-flash-latest\", temperature=0.2, google_api_key=GOOGLE_API_KEY)\n",
        "\n"
      ],
      "metadata": {
        "id": "LDzzl5PwdkhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 3: Node to ask user for symptom"
      ],
      "metadata": {
        "id": "o07zbkLWcOVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_symptoms(state: dict)-> dict:\n",
        "  symptom=input(\"welcome to hospital enter your symptom\")\n",
        "  state[\"symptom\"]= symptom\n",
        "  return state"
      ],
      "metadata": {
        "id": "3KWcEaYceYLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4: Node to classify the symptom"
      ],
      "metadata": {
        "id": "0KIzyYPVcRVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_symptom(state: dict)-> dict:\n",
        " prompt =(\n",
        "     \"Act like a health agent yourduty is to analyze the symptom that given to you \\n\"\n",
        "     \"General\\n -Emergency \\n -mental health \\n\"\n",
        "     f\"symptom: {state['symptom']} \\n\"\n",
        "     \"respond only with one word : General or emergency or mental health\"\n",
        "\n",
        " )\n",
        " response =llm.invoke([HumanMessage(content=prompt)])\n",
        " category=response.content.strip()\n",
        " print(f\"LLM classifies the symptom as : {category}\")\n",
        " state[\"category\"]=category\n",
        " return state"
      ],
      "metadata": {
        "id": "C6ig9UL2gW24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 5: Router logic to route to the correct node\n"
      ],
      "metadata": {
        "id": "kESmxbnicWpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def symptom_router(state:dict) -> dict:\n",
        " cat=state[\"category\"].lower()\n",
        " if \"general\" in cat:\n",
        "  return \"general\"\n",
        " elif \"mental health\" in cat:\n",
        "   return \"mental health\"\n",
        " else:\n",
        "    return \"emergency\""
      ],
      "metadata": {
        "id": "RmXfF0ZQihml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 6: Category-specific response nodes\n"
      ],
      "metadata": {
        "id": "cZuR4VGscake"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def general_node(state: dict)->dict:\n",
        "  state[\"answer\"] =f\"{state ['symptom']}' :seems general:directingyou to general ward for consulting a doctor\"\n",
        "  return state\n",
        "def mental_node(state: dict)-> dict:\n",
        "  state[\"answer\"] =f\"{state ['symptom']}' :seems Mental:directingyou to go Mental ward for immediate admit\"\n",
        "  return state\n",
        "def emergency_node(state: dict)-> dict:\n",
        "  state[\"answer\"] =f\"{state ['symptom']}' :seems Emergency:directingyou to go emergency ward for immidiate admit\"\n",
        "  return state\n"
      ],
      "metadata": {
        "id": "f9LUjPL4KMEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 7: Build LangGraph\n"
      ],
      "metadata": {
        "id": "I1ek0SwzcehS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "builder = StateGraph(dict)\n",
        "builder.set_entry_point(\"get_symptoms\")\n",
        "builder.add_node(\"get_symptoms\",get_symptoms)\n",
        "builder.add_node(\"classify_symptom\",classify_symptom)\n",
        "builder.add_node(\"general\",general_node)\n",
        "builder.add_node(\"mental health\",mental_node)\n",
        "builder.add_node(\"emergency\",emergency_node)\n",
        "\n",
        "builder.add_conditional_edges(\"classify_symptom\",symptom_router,{\n",
        "  \"general\":\"general\",\n",
        "  \"mental health\":\"mental health\",\n",
        "  \"emergency\":\"emergency\"\n",
        "})\n",
        "builder.add_edge(\"get_symptoms\",\"classify_symptom\")\n",
        "builder.add_edge(\"general\",END)\n",
        "builder.add_edge(\"mental health\",END)\n",
        "builder.add_edge(\"emergency\",END)"
      ],
      "metadata": {
        "id": "PPgaii9uMV0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 8: Compile and invoke the graph\n"
      ],
      "metadata": {
        "id": "GbAgCeZYci5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph = builder.compile()\n",
        "final_State=graph.invoke({})\n",
        "print(\"final Output \\n\")\n",
        "print(final_State[\"answer\"])"
      ],
      "metadata": {
        "id": "JR4nUjTOThLv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}